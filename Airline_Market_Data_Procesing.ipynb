{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou2S5zlbOOnX"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-qlFXV8OY1w"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pUqm4DcFLdSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import os\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "path= os.path.abspath(glob.glob(\"**\")[1]).replace(\"\\\\\", '/' ) + \"/\" #! Path definition \n",
        "file_aero = 'Aerocivil.txt' #! File definition \n",
        "file_price = 'Precios.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuZjKzAiOT82"
      },
      "source": [
        "## Quantities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8O5WEivOb53"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ZN57JgW8LlXW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\navas.LAPTOP-5SHC5PM9\\AppData\\Local\\Temp\\ipykernel_23624\\4154963715.py:3: DtypeWarning: Columns (3,4,5,18,24,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(p_f, sep=\"\\t\")\n"
          ]
        }
      ],
      "source": [
        "# Processing of quantities table\n",
        "p_f =  path + file_aero\n",
        "data = pd.read_csv(p_f, sep=\"\\t\")\n",
        "df =data\n",
        "df = df.replace('(en blanco)', '0') \n",
        "\n",
        "df =df[['Año','Mes', 'CiudadDestino','Destino','Destino_MC',\n",
        "        'NombreAeropuertoDestino','CiudadOrigen','Origen','Origen_MC', \n",
        "        'NombreAeropuertoOrigen','Leg', 'MarketLeg','Airline_Cod',\n",
        "        'NombredeEmpresa','SiglaEmpresa','Trafico','TipoVuelo','Ruta_Viva',\n",
        "        'NumerodeVuelos','PasajerosABordo','PasajerosTransito',\n",
        "        'SillasOfrecidas','KM','LF','PDEWS','Weekly_Frequencies']]\n",
        "\n",
        "df =df.sort_values(['Año','Mes','MarketLeg']).reset_index()\n",
        "\n",
        "df[['KM',\t'LF',\t'PDEWS','Weekly_Frequencies']]=df[['KM',\t'LF',\t'PDEWS',\n",
        "                                        'Weekly_Frequencies']].astype('string')\n",
        "\n",
        "\n",
        "for x in ['KM',\t'LF',\t'PDEWS','Weekly_Frequencies']: \n",
        "  df[x]=df[x].apply(lambda x: x.replace(',', '.'))\n",
        "\n",
        "  \n",
        "df[['NumerodeVuelos',\t'PasajerosABordo',\t'PasajerosTransito',\t\n",
        "    'SillasOfrecidas','KM',\t'LF',\n",
        "    'PDEWS','Weekly_Frequencies']]=df[['NumerodeVuelos',\t'PasajerosABordo',\t\n",
        "                                      'PasajerosTransito',\t'SillasOfrecidas',\n",
        "                                      'KM',\t'LF','PDEWS',\n",
        "                                      'Weekly_Frequencies']].astype('float')\n",
        "\n",
        "df['Date'] = df['Mes'].astype('string')  + df['Año'].astype('string')\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%m%Y')\n",
        "\n",
        "# Creating data groups\n",
        "\n",
        "df['Company'] = df['Airline_Cod'].apply(lambda x: 'Other' if x != 'AV'and\n",
        "                                        x != 'LA' and\n",
        "                                        x != 'VH' and\n",
        "                                        x != 'VE'\n",
        "                                      else ('Avianca' if x == 'AV' \n",
        "                                          else ('Latam' if x == 'LA' \n",
        "                                            else ('Viva' if x == 'VH' \n",
        "                                              else('Easy Fly' if x=='VE' \n",
        "                                                else 'no match')))))\n",
        "\n",
        "\n",
        "df['Leg'] = df['Leg'].str.replace('EOH', 'MDE')\n",
        "df['MarketLeg'] = df['MarketLeg'].str.replace('EOH', 'MDE')\n",
        "df['Origen'] = df['Origen'].str.replace('EOH', 'MDE')\n",
        "df['Destino'] = df['Destino'].str.replace('EOH', 'MDE')\n",
        "df['CiudadDestino'] =df['CiudadDestino'].str.replace('RIONEGRO - ANTIOQUIA',\n",
        "                                                    'MEDELLIN')\n",
        "df['CiudadOrigen'] =df['CiudadOrigen'].str.replace('MEDELLIN', \n",
        "                                                  'RIONEGRO - ANTIOQUIA')\n",
        "df['Ruta_Viva'] = (df['Ruta_Viva'].str.replace('Si', '1')).astype('float')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "681xkF3aOfmS"
      },
      "source": [
        "### Data Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "zW9pu7_xMDvE"
      },
      "outputs": [],
      "source": [
        "# Creating df and df_full\n",
        "# df is defined as a regular and national flight after 2021\n",
        "df= df[(df['TipoVuelo'] == \"R\") & (df['Trafico'] == \"N\")  & (df['Año']>= 2021)].reset_index()\n",
        "# Dropping Level_0\n",
        "df.drop(['level_0'], axis=1, inplace = True)\n",
        "\n",
        "# df_full is defined as a regular and national flight at any time in the observation data (from 2011-2022)\n",
        "df_full = df[(df['TipoVuelo'] == \"R\") & (df['Trafico'] == \"N\")].reset_index()\n",
        "\n",
        "# Changing the airline code of Ultra Air\n",
        "df['Airline_Cod']=df['Airline_Cod'].replace('ULS', 'OL')\n",
        "\n",
        "# Deleting airlines that are not listed in the pricing data\n",
        "df = df[(df['Airline_Cod']!= 'CM') & (df['Airline_Cod']!= 'OTROS') ]\n",
        "\n",
        "# We grouped the data to delete duplicates\n",
        "\n",
        "df=df.groupby(['Año','Mes','Date', 'CiudadDestino','Destino','Destino_MC',\n",
        "            'CiudadOrigen','Origen','Origen_MC','Leg' , 'MarketLeg',\n",
        "            'Airline_Cod','Company','Trafico','TipoVuelo'] ,\n",
        "            as_index=False).agg({'Ruta_Viva':'sum','NumerodeVuelos':'sum', \n",
        "                                'NumerodeVuelos':'sum',\n",
        "                                'PasajerosABordo':'sum',\n",
        "                                'PasajerosTransito':'sum',\n",
        "                                'SillasOfrecidas':'sum',\n",
        "                                'KM':'mean','LF':'mean',\n",
        "                                'PDEWS':'mean','Weekly_Frequencies':'mean' })\n",
        "    \n",
        "\n",
        "df_full=df_full.groupby(['Año','Mes','Date', 'CiudadDestino','Destino',\n",
        "                        'Destino_MC','CiudadOrigen','Origen','Origen_MC',\n",
        "                        'Leg', 'MarketLeg','Airline_Cod','Company' ,\n",
        "                        'Trafico','TipoVuelo'] ,\n",
        "                        as_index=False).agg({'Ruta_Viva':'sum',\n",
        "                                            'NumerodeVuelos':'sum', \n",
        "                                            'NumerodeVuelos':'sum',\n",
        "                                            'PasajerosABordo':'sum',\n",
        "                                            'PasajerosTransito':'sum',\n",
        "                                            'SillasOfrecidas':'sum',\n",
        "                                            'KM':'mean','LF':'mean',\n",
        "                                            'PDEWS':'mean',\n",
        "                                            'Weekly_Frequencies':'mean' })\n",
        "# we reduce the sample to one-year observation level\n",
        "df['Date'] = pd.to_datetime(df['Date']).dt.to_period('M')\n",
        "df = df[df['Date']>= '2021-02']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYa8B7LSPZfy"
      },
      "source": [
        "### New Variables and measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fIY9SmEoPQO2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\navas.LAPTOP-5SHC5PM9\\AppData\\Local\\Temp\\ipykernel_23624\\3825487084.py:40: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  treatment = df.groupby(['Date','Leg'],\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# We create the HH index for passengers on board by route and period\n",
        "mk_share_for_hhi = df.groupby(['Date','Leg','Airline_Cod'], \n",
        "                              as_index=False)['PasajerosABordo'].agg('sum')\n",
        "                              \n",
        "mk_share_for_hhi['id_HHI_treatment'] = mk_share_for_hhi['Date'].astype(str) + mk_share_for_hhi['Leg']\n",
        "mk_share_for_hhi['id_m_share'] = mk_share_for_hhi['Date'].astype(str) + mk_share_for_hhi['Leg'] + mk_share_for_hhi['Airline_Cod']\n",
        "\n",
        "consol_hhi =df.groupby(['Date', 'Leg'],\n",
        "                      as_index=False)['PasajerosABordo'].agg('sum')\n",
        "\n",
        "consol_hhi.rename(columns = {'PasajerosABordo':'PasajerosABordo_sum'}, \n",
        "                  inplace = True)\n",
        "\n",
        "consol_hhi['id_HHI_treatment'] = consol_hhi['Date'].astype(str) + consol_hhi['Leg']\n",
        "mk_share_for_hhi = mk_share_for_hhi.merge(consol_hhi, on='id_HHI_treatment', \n",
        "                                          how='left')\n",
        "\n",
        "# We create the Market Share for passengers on board by airline, route and period\n",
        "mk_share_for_hhi['m_share'] = (mk_share_for_hhi['PasajerosABordo']/ mk_share_for_hhi['PasajerosABordo_sum'])\n",
        "df['id_m_share'] = df['Date'].astype(str) + df['Leg'] +df['Airline_Cod']\n",
        "df_m_share = mk_share_for_hhi[['id_m_share', 'm_share']]\n",
        "df = df.merge(df_m_share, on='id_m_share', how='left')\n",
        "\n",
        "\n",
        "\n",
        "mk_share_for_hhi['HHI'] = (mk_share_for_hhi['m_share'].pow(2,axis=0))\n",
        "\n",
        "mk_share_for_hhi = mk_share_for_hhi.groupby(['id_HHI_treatment','Date_x', 'Leg_x'], as_index=False)['HHI'].agg('sum')\n",
        "\n",
        "df['id_HHI_treatment'] = df['Date'].astype(str) + df['Leg']\n",
        "mk_share_for_hhi = mk_share_for_hhi[['id_HHI_treatment', 'HHI']]\n",
        "df = df.merge(mk_share_for_hhi, on='id_HHI_treatment', how='left')\n",
        "\n",
        "\n",
        "# We create the future treatment and pre-post variables by  route and period\n",
        "df['OL_Presence'] =np.where(df['Airline_Cod'] == 'OL', 1, 0)\n",
        "df['OL_entrance'] =np.where(df['Date'] > '2022-03', 1, 0)\n",
        "\n",
        "\n",
        "treatment = df.groupby(['Date','Leg'], \n",
        "                      as_index=False)['OL_Presence','OL_entrance'].agg('sum')\n",
        "TREATMENT = ['OL_Presence','OL_entrance']\n",
        "\n",
        "for i in TREATMENT:\n",
        "  treatment[i] = np.where(treatment[i]>=1,1,0)\n",
        "\n",
        "df = df.drop(columns=['OL_Presence','OL_entrance'])\n",
        "\n",
        "\n",
        "treatment_2 = treatment.groupby('Leg', as_index = False)['OL_Presence'].agg(sum)\n",
        "TREATMENT_2 = ['OL_Presence']\n",
        "\n",
        "\n",
        "for i in TREATMENT_2:\n",
        "  treatment_2[i] = np.where(treatment_2[i]>=1,1,0)\n",
        "  \n",
        "\n",
        "treatment = treatment[[ 'OL_entrance', 'Leg', 'Date']]\n",
        "treatment = treatment.merge(treatment_2, on='Leg', how='left')\n",
        "\n",
        "treatment['id_HHI_treatment'] = treatment['Date'].astype(str) + treatment['Leg']\n",
        "treatment = treatment[['id_HHI_treatment', 'OL_Presence','OL_entrance']]\n",
        "\n",
        "df = df.merge(treatment, on='id_HHI_treatment', how='left')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W02PW4oXTH0N"
      },
      "source": [
        "## Prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otLxUGtqVB7x"
      },
      "source": [
        "### Data Cleaning and sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "64h_yvlLTOy1"
      },
      "outputs": [],
      "source": [
        "#  Processing of prices table\n",
        "p_f_p =  path + file_price\n",
        "df_p = pd.read_csv(p_f_p, sep=\"\\t\")\n",
        "\n",
        "df_p[['fullprice',\t'Netprice', 'tax']]=df_p[['fullprice',\t'Netprice', 'tax']].astype('string')\n",
        "\n",
        "for x in ['fullprice',\t'Netprice', 'tax']: \n",
        "  df_p[x]=df_p[x].apply(lambda x: x.replace(',', '.'))\n",
        "\n",
        "df_p[['fullprice',\t'Netprice', 'tax']]=round(df_p[['fullprice',\t'Netprice', 'tax']].astype('float'),2)\n",
        "\n",
        "df_p['ObservationDate'] = pd.to_datetime(df_p['ObservationDate'], format='%Y-%m-%d')\n",
        "df_p['Depdate'] = pd.to_datetime(df_p['Depdate'], format='%Y-%m-%d')\n",
        "\n",
        "df_p['Año'], df_p['Mes'], df_p['Dia'] = pd.to_datetime(df_p['Depdate']).dt.year, pd.to_datetime(df_p['Depdate']).dt.month, pd.to_datetime(df_p['Depdate']).dt.day\n",
        "df_p['Month-Year'] =  pd.to_datetime(df_p['Depdate']).dt.to_period('M')\n",
        "\n",
        "df_p['Leg'] = df_p['Leg'].str.replace('EOH', 'MDE')\n",
        "df_p =df_p.sort_values(['Año','Mes','Leg']).reset_index()\n",
        "\n",
        "# We sampling data from 2021-08 to 2022-08\n",
        "df_p = df_p[(df_p['Month-Year']<='2022-08')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkwDcYk7U4B0"
      },
      "source": [
        "### New Variables and Data grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "8SptpOsLU9g3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\navas.LAPTOP-5SHC5PM9\\AppData\\Local\\Temp\\ipykernel_23624\\849820958.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  df_p = df_p.groupby(['Año','Mes','Month-Year','Carrier','Leg','Days for depature'], as_index=False)['Netprice','fullprice','tax'].agg('mean')\n"
          ]
        }
      ],
      "source": [
        "# We create a new variable that indicates the number of days for the flight departure. \n",
        "df_p['Days for depature'] = ( df_p['ObservationDate']-df_p['Depdate'] )\n",
        "df_p =df_p.sort_values(['Depdate','Days for depature'])\n",
        "df_p['Days for depature']= df_p['Days for depature'].dt.days\n",
        "\n",
        "# We grouped by month \n",
        "df_p = df_p.groupby(['Año','Mes','Month-Year','Carrier','Leg','Days for depature'], as_index=False)['Netprice','fullprice','tax'].agg('mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3bYlB_UWKj9"
      },
      "source": [
        "## Joining quantities and prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5GrTbv9TVmKc"
      },
      "outputs": [],
      "source": [
        "# We define new data frames\n",
        "df_APP1 = df\n",
        "df_p_month_day_APP1 = df_p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_eEI95ABW9oX"
      },
      "outputs": [],
      "source": [
        "# We pivot the price data\n",
        "df_p_month_day_pivot_APP1 = df_p_month_day_APP1.pivot( index =[ 'Año','Mes','Month-Year','Carrier',\"Leg\"], columns=['Days for depature'], values=['fullprice'])\n",
        "df_p_month_day_pivot_APP1.columns = df_p_month_day_pivot_APP1.columns.droplevel(0) \n",
        "df_p_month_day_pivot_APP1.columns.name = None\n",
        "df_p_month_day_pivot_APP1 = df_p_month_day_pivot_APP1.reset_index()\n",
        "\n",
        "# We create an ID code (year + month + airline + route ) \n",
        "df_p_month_day_pivot_APP1['id'] = df_p_month_day_pivot_APP1['Año'].astype(str) + df_p_month_day_pivot_APP1['Mes'].astype(str) + df_p_month_day_pivot_APP1['Carrier'] +df_p_month_day_pivot_APP1['Leg']\n",
        "df_APP1['id'] = df_APP1['Año'].astype(str) + df_APP1['Mes'].astype(str) + df_APP1['Airline_Cod'] +df_APP1['Leg']\n",
        "\n",
        "# We condition the presence of data in our samples in order to develop the join exercise further.\n",
        "df_APP1 = df_APP1[df_APP1['Leg'].isin(list(df_p.groupby('Leg', as_index = False).count()['Leg']))]\n",
        "df_p_month_day_pivot_APP1 = df_p_month_day_pivot_APP1[df_p_month_day_pivot_APP1['id'].isin(list(df_APP1.groupby('id', as_index = False).count()['id']))]\n",
        "df_APP1 = df_APP1[df_APP1['id'].isin(list(df_p_month_day_pivot_APP1.groupby('id', as_index = False).count()['id']))]\n",
        "\n",
        "# We drop some columns that we do not use\n",
        "df_p_month_day_pivot_APP1 = df_p_month_day_pivot_APP1.drop(columns=['Año','Mes','Month-Year','Carrier','Leg'])\n",
        "\n",
        "# We join the Data\n",
        "full_data_APP1 = pd.merge(df_APP1,df_p_month_day_pivot_APP1, on=[\"id\",\"id\"])\n",
        "full_data_APP1= full_data_APP1.sort_values(['Date','Leg'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lgycvXlayPq"
      },
      "source": [
        "### Data processing verification and export \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:/Users/navas.LAPTOP-5SHC5PM9/OneDrive - Universidad EAFIT/GitHub/Colombian-Air-Market-Data-Processing/Data_for_regresions_APP_1.xlsx'"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "os.path.abspath(glob.glob('*/')[0]).replace(\"\\\\\", '/' ).replace(\"/Data\", '/Data_for_regresions_APP_1.xlsx' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wU8NJG8auLB"
      },
      "outputs": [],
      "source": [
        "\n",
        "if full_data_APP1['id'].nunique()/ len(full_data_APP1)==1 :\n",
        "\n",
        "  # To excel\n",
        "  full_data_APP1.to_excel(os.path.abspath(glob.glob('*/')[0]).replace(\"\\\\\", '/' ).replace(\"/Data\", '/Data_for_regresions_APP_1.xlsx' ))\n",
        "  # To stata\n",
        "  full_data_APP1_to_stata = full_data_APP1\n",
        "  full_data_APP1_to_stata['Date'] = full_data_APP1_to_stata['Año'].astype(str)+'-' +full_data_APP1_to_stata['Mes'].astype(str)\n",
        "  full_data_APP1_to_stata.to_stata(os.path.abspath(glob.glob('*/')[0]).replace(\"\\\\\", '/' ).replace(\"/Data\", '/Data_for_regresions_APP_1.dta' ))\n",
        "\n",
        "  print('The join exercise was successfully developed. We do not have duplicates')\n",
        "\n",
        "else:\n",
        "  print(\"We need to review de data processing. An error was made\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STATA CODES AND PROCESSING"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regressions: estimation and  Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "import stata_setup\n",
        "#For windows \n",
        "stata_setup.config('C:/Program Files/Stata17/', 'mp')\n",
        "\n",
        "# For linux 'uncomment' the following line\n",
        "#stata_setup.config(\"/usr/local/stata17/\", \"mp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "\n",
        "global path  \"`c(pwd)'\"\n",
        "use \"$path\\Data_for_regresions_APP_1.dta\", clear\n",
        "\n",
        "* # Creacion de variables\n",
        "drop index\n",
        "tostring A_o Mes, gen(A_o_s Mes_s)\n",
        "gen idLEG = A_o_s + Mes_s + Leg\n",
        "drop  A_o_s Mes_s\n",
        "rename m_share ms\n",
        "*CREEMOS EL FACTOR DE OCUPACION\n",
        "gen of = PasajerosABordo/SillasOfrecidas\n",
        "\n",
        "* # IDENTIFIQUEMOS CUALES SON LAS RUTAS QUE SIEMPRE SON UNICAS\n",
        "preserve\n",
        "egen HHI_1 = total(HHI==1) , by(Leg)\n",
        "keep if HHI_1!=0 \n",
        "collapse (mean) HHI, by(Leg)\n",
        "keep if HHI==1\n",
        "ren HHI index_HHI\n",
        "save \"$path\\Leg_HHI_1_ever.dta\", replace\n",
        "restore\n",
        "\n",
        "merge m:1 Leg using \"$path\\Leg_HHI_1_ever.dta\", update replace\n",
        "erase \"$path\\Leg_HHI_1_ever.dta\"\n",
        "drop _merge\n",
        "\n",
        "\n",
        "* # IDENTIFIQUEMOS LAS PRINCIPALES RUTAS\n",
        "preserve\n",
        "use \"$path\\Data_for_regresions_APP_1_MONTH_LEG.dta\", clear\n",
        "rename id idLEG\n",
        "egen rank= rank(-PasajerosABordo), by( Date)\n",
        "gen top_30 = (rank<=30)\n",
        "gen top_30_plus = (rank>30)\n",
        "sort A_o Mes Leg rank\n",
        "keep idLEG rank top_30 top_30_plus\n",
        "save \"$path\\RANKS_FOR_LEG.dta\", replace\n",
        "\n",
        "restore\n",
        "merge m:1 idLEG using \"$path\\RANKS_FOR_LEG.dta\", update replace\n",
        "erase \"$path\\RANKS_FOR_LEG.dta\"\n",
        "drop _merge\n",
        "\n",
        "\n",
        "* # CREEMOS UNA VARIABLE PARA Alta y baja ocupacion\n",
        "preserve\n",
        "collapse (sum) PasajerosABordo SillasOfrecidas, by(Leg)\n",
        "gen OF =PasajerosABordo/SillasOfrecidas\n",
        "gen index_OF = (OF>=0.8)\n",
        "keep Leg index_OF\n",
        "save \"$path\\RANKS_FOR_LEG_OF.dta\", replace\n",
        "restore\n",
        "merge m:1 Leg using \"$path\\RANKS_FOR_LEG_OF.dta\", update replace\n",
        "erase \"$path\\RANKS_FOR_LEG_OF.dta\"\n",
        "drop _merge\n",
        "\n",
        "\n",
        "* # CREEMOS UN FORMATO PARA LA FECHA\n",
        "gen Date_2 =mofd( date(Date,\"YM\"))\n",
        "format Date_2 %tm\n",
        "* CREEMOS UNA VARIABLE A PARTIR DE NOVIEMBRE\n",
        "gen Date_after_nov = (Date_2 >= 742)\n",
        "\n",
        "* # CREEMOS ID PARA LEG Y AEROLINEA\n",
        "egen id_leg_car =  group( Leg Airline_Cod)\n",
        "egen id_car =  group( Airline_Cod)\n",
        "egen id_leg =  group( Leg)\n",
        "xtset id_leg_car Date_2\n",
        "\n",
        "* # CREATE Vars in LOG\n",
        "gen ln_HHI = log(HHI)\n",
        "forvalues i = 0(1)150 {\n",
        "\tcapture noisily gen ln_`i' = log(_`i') \n",
        "}\n",
        "\n",
        "\n",
        "* # creemos un rank de lideres de ruta\n",
        "egen rank_MS= rank(-ms), by(Leg Date)\n",
        "gen follower = (rank_MS!=1)\n",
        "\n",
        "\n",
        "**# instrument regression selection\n",
        "\n",
        "gen interact_OL =  OL_Presence*OL_entrance\n",
        "\n",
        "**# OPTIONAL(new vars creations)\n",
        "keep if index_HHI!=1\n",
        "keep if Date_after_nov==1\n",
        "gen Date_after_dic= (Date_2>= 743)\n",
        "gen Date_after_jan= (Date_2>= 744)\n",
        "\n",
        "* # REGRESIONES\n",
        "\t\t\t\t\n",
        "matrix HAUSMANTEST=J(151,4,.)\n",
        "\t\t\tlocal row=1\n",
        "\t\t\tforvalues i = 0(1)150 {\n",
        "\t\t\t\t\test clear\n",
        "\t\t\t\t\tcapture noisily quietly ivreghdfe ln_`i' (ln_HHI = interact_OL ) , first ffirst savefirst  absorb(id_leg Date_2) \n",
        "\t\t\t\t\tcapture noisily mat HAUSMANTEST[`row',3] = e(widstat)\n",
        "\t\t\t\t\tcapture noisily mat HAUSMANTEST[`row',4] = e(N)\n",
        "\t\t\t\t\tcapture noisily estimates store iv_reg\n",
        "\t\t\t\t\tcapture noisily quietly reghdfe ln_`i' ln_HHI , absorb(id_leg Date_2 )\n",
        "\t\t\t\t\tcapture noisily estimates store noiv_reg\n",
        "\t\t\t\t\tcapture noisily hausman iv_reg noiv_reg\t\n",
        "\t\t\t\t\tcapture noisily mat HAUSMANTEST[`row',1] = r(p)\n",
        "\t\t\t\t\tcapture noisily sum interact_OL if ln_`i'!=.\n",
        "\t\t\t\t\tcapture noisily mat HAUSMANTEST[`row',2] = r(mean)\n",
        "\n",
        "\t\t\t\tlocal row = `row'+1\n",
        "\t\t\t\t\n",
        "\t\t\t}\t\t\t\t\n",
        "\t\t\t\t\n",
        "matsave HAUSMANTEST, replace saving path(\"$path/ESTADISTICAS_RUTAS\")\n",
        "\n",
        "\n",
        "\n",
        "global LNHHI_IV_1  \"\"(ln_HHI = interact_OL ) \" \"(ln_HHI = interact_OL ) if  Date_after_dic==1 \" \"(ln_HHI = interact_OL ) if Date_after_jan==1 \"   \"(ln_HHI = interact_OL ) if (top_30==1 )\" \"(ln_HHI = interact_OL ) if (top_30_plus==1 )\" \"(ln_HHI = interact_OL ) if rank_MS==1  \" \"(ln_HHI = interact_OL ) if rank_MS!=1  \" \"(ln_HHI = interact_OL ) if index_OF!=1  \" \"(ln_HHI = interact_OL ) if index_OF==1  \"\" \n",
        "\n",
        "\n",
        "global FE \"\"id_leg\"\"\n",
        "global RC \"\"robust\"\"\n",
        "\n",
        "\n",
        "global REG \"$LNHHI_IV_1\"\n",
        "\n",
        "foreach rc in $RC {\n",
        "\tforeach fe in $FE {\n",
        "\t\tforeach p in $REG {\n",
        "\t\t\t\n",
        "\t\t\tlocal replace replace\n",
        "\t\t\tforvalues i = 0(1)150 {\n",
        "\t\t\t\t\tcapture noisily quietly ivreghdfe ln_`i' `p' , first ffirst savefirst  absorb(`fe' Date_2) `rc' \n",
        "\t\t\t\t\tcapture noisily quietly estimates replay _ivreg2_ln_HHI\n",
        "\t\t\t\t\tlocal w : display %9.4f r(table)[\"b\", \"interact_OL\"]\n",
        "\t\t\t\t\tlocal w2 : display %9.4f r(table)[\"se\", \"interact_OL\"]\n",
        "\t\t\t\t\tlocal w3 : display %9.4f r(table)[\"t\", \"interact_OL\"]\n",
        "\t\t\t\t\tlocal w4 : display %9.4f r(table)[\"pvalue\", \"interact_OL\"]\n",
        "\t\t\t\t\tlocal w5 : display %9.4f r(table)[\"ll\", \"interact_OL\"]\n",
        "\t\t\t\t\tlocal w6 : display %9.4f r(table)[\"ul\", \"interact_OL\"]\n",
        "\t\t\t\t\tregsave ln_HHI using \"$path/Regressions_Results/reg_1_`fe'_`rc'_`p'.dta\", ci level(90) addlabel(lags, _`i',F, `e(widstat)', coef_f1, `w', se, `w2', t_value, `w3', pvalue, `w4', ll, `w5', ul, `w6') `replace'\n",
        "\t\t\t\t\tlocal replace append \n",
        "\t\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "local filenames : dir \"$path\\Regressions_Results\" files \"*.dta\"\n",
        "\t\n",
        "\tforeach f in `filenames' {\n",
        "\t\t\t\n",
        "\t\tuse \"$path\\Regressions_Results\\\\`f'\", replace\n",
        "\t\treplace lags = subinstr(lags, \"_\", \"-\",.)\n",
        "\t\tdestring lags, replace\n",
        "\t\tsum(F)\n",
        "\t\tlocal w : display %9.4f r(mean)\n",
        "\t\ttwoway  (rcap ci_lower ci_upper lags, fcolor(none)  lcolor(gray)) (scatter coef \tlags, mcolor(black) msize(small) \t\t\t///\n",
        "\t\tlcolor(black)), legend(order(2 \"Coeff\" 1 \"90% CI\") region(lwidth(none))) \t\t///\n",
        "\t\tyline(0) xscale(range(0, -150)) xlabel(0(10)-150)  graphregion(color(white)) \t\t///\n",
        "\t\tytitle(coefficient) xtitle(Lags, m(medsmall)) yscale(range(-1, 1.5)) ylabel(-1(0.5)1.5) caption(\"{bf:First stage F-value}: `w'\", size(*0.75))\n",
        "\t\tlocal fnew = subinstr(\"`f'\",\".dta\",\".png\",.)\n",
        "\t\tgraph export  \"$path\\Regressions_Graphs\\\\`fnew'\", replace\n",
        "\t\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analytics and Empirical test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "\n",
        "# /*\n",
        "\n",
        "# ESTE CODIGO SE DEBE CORRER DESPUES DE LAS REGRESIONES\n",
        "\n",
        "# Este codigo tiene como objetivo crear todas las estadisticas descriptivas  y empiricas\n",
        "# de la estrategia de identificacion (tendecias paralelas y diseno de estudio de evento)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# */\n",
        "global path  \"`c(pwd)'\"\n",
        "use \"$path\\Data_for_trends.dta\", clear\n",
        "\n",
        "* Creacion de variables\n",
        "drop index\n",
        "drop if Airline_Cod==\"AA\"\n",
        "drop if Airline_Cod==\"9A\"\n",
        "tostring A_o Mes, gen(A_o_s Mes_s)\n",
        "gen idLEG = A_o_s + Mes_s + Leg\n",
        "drop  A_o_s Mes_s\n",
        "rename m_share ms\n",
        "\n",
        "\n",
        "\n",
        "* CREEMOS UN FORMATO PARA LA FECHA\n",
        "gen Date_2 =mofd( date(Date,\"YM\"))\n",
        "format Date_2 %tm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "* # TEDENCIAS PARALELAS\n",
        "preserve\n",
        "collapse (mean) HHI (sem) m_HHI= HHI, by(Date_2 OL_Presence)\n",
        "keep if Date_2>=735\n",
        "gen U_B = HHI+ m_HHI\n",
        "gen L_B = HHI - m_HHI\n",
        "twoway(rarea  U_B L_B Date_2 if OL_Presence==1,   fcolor(navy) lwidth(none)  fintensity(30)) (rarea  U_B L_B Date_2 if OL_Presence==0, fcolor(gray) lwidth(none)  fintensity(30)) (line HHI Date_2 if OL_Presence==0, lcolor(gray)) (line HHI Date_2 if OL_Presence==1, lcolor(navy)) ,  legend(order(4 \"Treatment group routes\" 3 \"Control group routes\") region(lwidth(none))) \t\t///\n",
        "\t\tyline(0, lcolor(black)) xline(745)  graphregion(color(white)) \t\t///\n",
        "\t\tytitle(\"HHI\") xtitle(Date, m(medsmall))  caption(\"{bf:Note}: The vertical line indicates Ultra's entry into the market (in February 2022)\", size(*0.75))\n",
        "\t\t\n",
        "restore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "%%stata\n",
        "preserve\n",
        "* # COMO ES EL EFECTO DE LA ENTRADA DE RUTA A NIVEL RUTA\n",
        "collapse (mean) HHI (sem) m_HHI= HHI, by(Date_2 OL_Presence MarketLeg)\n",
        "keep if Date_2>=735\n",
        "gen U_B = HHI+ m_HHI\n",
        "gen L_B = HHI - m_HHI\n",
        "keep if OL_Presence==1\n",
        "\n",
        "\n",
        "\t\t\n",
        "xtline HHI , i(MarketLeg) t(Date_2) overlay  legend(region(lwidth(none)))  xline(745) \n",
        "\n",
        "restore\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "preserve \n",
        "keep if Date_2>=735\n",
        "collapse (sum) PasajerosABordo (mean) HHI  (sem) m_HHI= HHI, by(OL_entrance OL_Presence MarketLeg)\n",
        "egen rank= rank(-PasajerosABordo), by(OL_entrance)\n",
        "gen U_B = HHI+ m_HHI\n",
        "gen L_B = HHI - m_HHI\n",
        "\n",
        "twoway (scatter HHI rank if (OL_entrance==0 & OL_Presence==1))(qfit HHI rank if (OL_entrance==0 & OL_Presence==1))(scatter HHI rank if (OL_entrance==1 & OL_Presence==1) ) (qfit HHI rank if (OL_entrance==1 & OL_Presence==1)) (rcap L_B U_B rank if OL_Presence==1, fcolor(none)  lcolor(gray)), legend(order(1 \"Pretreatment\" 3 \"Postreatment\" 2 \"Pretreatment trend\" 4 \"Postreatment trend\") region(lwidth(none))) \t\t///\n",
        "\t\t   graphregion(color(white)) \t\t///\n",
        "\t\tytitle(\"HHI (mean)\") xtitle(Rank, m(medsmall)) title( \"Treatment Group\")\n",
        "\t\t\n",
        "\n",
        "\n",
        "keep if HHI!=1\n",
        "\t\t\n",
        "twoway (scatter HHI rank if (OL_entrance==0 & OL_Presence==0))(qfit HHI rank if (OL_entrance==0 & OL_Presence==0))(scatter HHI rank if (OL_entrance==1 & OL_Presence==0) ) (qfit HHI rank if (OL_entrance==1 & OL_Presence==0)) (rcap L_B U_B rank if OL_Presence==0, fcolor(none)  lcolor(gray)), legend(order(1 \"Pretreatment\" 3 \"Postreatment\" 2 \"Pretreatment trend\" 4 \"Postreatment trend\") region(lwidth(none))) \t\t///\n",
        "\t\t   graphregion(color(white)) \t\t///\n",
        "\t\tytitle(\"HHI (mean)\") xtitle(Rank, m(medsmall)) \n",
        "\t\t\n",
        "\n",
        "\n",
        "restore\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "# /*\n",
        "# Este codigo tiene como objetivo crear todas las estadisticas descriptivas  de market shares, pasajeros y sillas\n",
        "\n",
        "# */\n",
        "\n",
        "global path  \"`c(pwd)'\"\n",
        "use \"$path\\Data_for_trends.dta\", clear\n",
        "\n",
        "* Creacion de variables\n",
        "drop index\n",
        "drop if Airline_Cod==\"AA\"\n",
        "drop if Airline_Cod==\"9A\"\n",
        "tostring A_o Mes, gen(A_o_s Mes_s)\n",
        "gen idLEG = A_o_s + Mes_s + Leg\n",
        "drop  A_o_s Mes_s\n",
        "rename m_share ms\n",
        "\n",
        "\n",
        "* CREEMOS UN FORMATO PARA LA FECHA\n",
        "gen Date_2 =mofd( date(Date,\"YM\"))\n",
        "format Date_2 %tm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata \n",
        "\n",
        "preserve\n",
        "egen tot_pas =  total (PasajerosABordo), by(Date_2 Leg)\n",
        "keep Airline_Cod Leg Date_2  ms tot_pas\n",
        "reshape wide ms, i(Leg Date_2 tot_pas ) j(Airline_Cod) string\n",
        "\n",
        "global w \"ms9R msAV msLA msOL msP5 msVE msVH\"\n",
        " \n",
        "foreach i in $w {\n",
        "\treplace `i' = 0 if `i' ==.\n",
        "\t\n",
        "}\n",
        "reshape long ms, i(Leg Date_2 tot_pas ) j(Airline_Cod) string\n",
        "collapse (mean) ms (sem) m_ms = ms [fw=tot_pas], by(Date_2  Airline_Cod)\n",
        "\n",
        "gen U_B = ms+ m_ms\n",
        "gen L_B = ms - m_ms\n",
        "replace ms = .  if ms==0\n",
        "replace ms = ms*100\n",
        "\n",
        "twoway(line  ms Date_2 if Airline_Cod==\"AV\",   lcolor(cranberry) lwidth(medthick)) (line  ms Date_2 if Airline_Cod==\"VH\", lcolor(gold)  lwidth(medthick) ) (line  ms Date_2 if Airline_Cod==\"LA\",   lcolor(midblue)  lwidth(medthick) ) (line  ms Date_2 if Airline_Cod==\"VE\",   lcolor(green)  lwidth(medthick)) (line  ms Date_2 if Airline_Cod==\"OL\",  lwidth(medthick)  lcolor(orange)) ,  legend(order(1 \"Avianca\" 2 \"Viva\" 3 \"Latam\" 4 \"Easy Fly\" 5 \"Ultra\")  lwidth(medthick) region(lwidth(none))) \t\t///\n",
        "\t\t    graphregion(color(white)) \t\t///\n",
        "\t\tytitle(\"Market Share\") xtitle(Date, m(medsmall)) \n",
        "\t\t\n",
        "restore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%stata\n",
        "preserve\n",
        "egen tot_pas =  total (PasajerosABordo), by(Date_2 Leg)\n",
        "keep Airline_Cod Leg Date_2  PasajerosABordo SillasOfrecidas tot_pas\n",
        "reshape wide PasajerosABordo SillasOfrecidas, i(Leg Date_2 tot_pas ) j(Airline_Cod) string\n",
        "\n",
        "global w \"PasajerosABordo9R PasajerosABordoAV PasajerosABordoLA PasajerosABordoOL PasajerosABordoP5 PasajerosABordoVE PasajerosABordoVH SillasOfrecidas9R SillasOfrecidasAV SillasOfrecidasLA SillasOfrecidasOL SillasOfrecidasP5 SillasOfrecidasVE SillasOfrecidasVH\"\n",
        "\n",
        " \n",
        "foreach i in $w {\n",
        "\treplace `i' = 0 if `i' ==.\n",
        "\t\n",
        "}\n",
        "\n",
        "reshape long PasajerosABordo SillasOfrecidas, i(Leg Date_2 tot_pas ) j(Airline_Cod) string\n",
        "\n",
        "collapse (mean) PasajerosABordo SillasOfrecidas (sem) m_PasajerosABordo = PasajerosABordo  m_SillasOfrecidas = SillasOfrecidas [fw=tot_pas], by(Date_2 )\n",
        "\n",
        "gen U_B = PasajerosABordo+ m_PasajerosABordo\n",
        "gen L_B = PasajerosABordo - m_PasajerosABordo\n",
        "\n",
        "twoway(line  PasajerosABordo Date_2 ,   lcolor(cranberry) lwidth(medthick)) (line  SillasOfrecidas Date_2 , lcolor(midblue)  lwidth(medthick) )  ,  legend(order(1 \"Passengers \" 2 \"Offered  seats\" )  lwidth(medthick) region(lwidth(none))) \t\t///\n",
        "\t\t    graphregion(color(white)) \t\t///\n",
        "\t\tytitle(\"Passengers | Seats (mean) \") xtitle(Date, m(medsmall)) \n",
        "\t\t\n",
        "\n",
        "restore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "%%stata\n",
        "preserve\n",
        "collapse (sum) PasajerosABordo SillasOfrecidas, by(Date_2)\n",
        "replace PasajerosABordo = PasajerosABordo/1000000\n",
        "replace SillasOfrecidas = SillasOfrecidas/1000000\n",
        "\n",
        "\n",
        "twoway(line  PasajerosABordo Date_2 ,   lcolor(cranberry) lwidth(medthick)) (line  SillasOfrecidas Date_2 , lcolor(midblue)  lwidth(medthick) )  ,  legend(order(1 \"Passengers \" 2 \"Offered  seats\" )  lwidth(medthick) region(lwidth(none))) \t\t///\n",
        "\t\t    graphregion(color(white)) \t\t///\n",
        "\t\tytitle(Passengers | Seats (in millions), size(medsmall)) xtitle(Date, m(medsmall)) \n",
        "\n",
        "restore"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMWJEVLVsI/utLMFxjSnn9P",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "14da4635d9bc1c91defc0cda200d7b8cd379b4a348c119f5267a6ff93be5824f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
